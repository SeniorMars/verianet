<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Verification Demo</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
            background: #f5f5f5;
            padding: 20px;
            line-height: 1.6;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            padding: 30px;
        }
        h1 { color: #333; margin-bottom: 10px; }
        h2 { color: #555; margin: 30px 0 15px; font-size: 1.3em; }
        h3 { color: #666; margin: 20px 0 10px; font-size: 1.1em; }
        p { color: #666; margin-bottom: 15px; }
        .network-viz {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        canvas {
            border: 1px solid #ddd;
            border-radius: 4px;
            background: white;
        }
        .info-panel {
            background: #f9f9f9;
            padding: 15px;
            border-radius: 4px;
            border: 1px solid #e0e0e0;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        .digit-display {
            text-align: center;
            margin-bottom: 15px;
        }
        .digit-canvas {
            image-rendering: pixelated;
            border: 2px solid #333;
            margin: 10px 0;
        }
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin-top: 10px;
        }
        button {
            background: #007bff;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }
        button:hover { background: #0056b3; }
        .legend {
            display: flex;
            align-items: center;
            gap: 20px;
            margin: 15px 0;
            padding: 10px;
            background: #f0f0f0;
            border-radius: 4px;
            font-size: 0.9em;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .color-bar {
            width: 100px;
            height: 20px;
            background: linear-gradient(to right, #ffffe0, #ff4500);
            border: 1px solid #999;
        }
        .robustness-section {
            margin-top: 30px;
        }
        .robustness-section img {
            max-width: 100%;
            border: 1px solid #ddd;
            border-radius: 4px;
        }
        .tooltip {
            position: fixed;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 10px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.85em;
            pointer-events: none;
            z-index: 1000;
            display: none;
            max-width: 350px;
            white-space: pre-line;
        }
        .modal {
            display: none;
            position: fixed;
            z-index: 2000;
            left: 0;
            top: 0;
            width: 100%;
            height: 100%;
            overflow: auto;
            background-color: rgba(0, 0, 0, 0.8);
        }
        .modal-content {
            background-color: #fefefe;
            margin: 2% auto;
            padding: 20px;
            border: 1px solid #888;
            border-radius: 8px;
            width: 90%;
            max-width: 1200px;
        }
        .modal-close {
            color: #aaa;
            float: right;
            font-size: 28px;
            font-weight: bold;
            cursor: pointer;
        }
        .modal-close:hover,
        .modal-close:focus {
            color: #000;
        }
        .neuron-clickable {
            cursor: pointer;
        }
        .mechanistic-formula {
            background: #f0f8ff;
            border-left: 4px solid #4CAF50;
            padding: 15px;
            margin: 15px 0;
            font-size: 1.1em;
            text-align: center;
        }
        .formula-box {
            background: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 15px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            font-size: 0.95em;
        }
        .math-section {
            background: #fafafa;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            padding: 20px;
            margin: 20px 0;
        }
        .polytope-explanation {
            background: #fff9e6;
            border: 2px solid #ffc107;
            border-radius: 6px;
            padding: 20px;
            margin: 20px 0;
        }
        code {
            background: #e9ecef;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Neural Network Interpretability Demo</h1>
        <p>
            We created a very small neural network with <strong>GELU-GELU-Linear</strong> architecture
            (49 → 3 → 3 → 10) for MNIST digit classification, with <strong>Softmax</strong> for post-processing
            to obtain class probabilities. This tiny network allows us to build exact polytope representations
            using linear programming.
        </p>

        <div class="math-section">
            <h3>Mathematical Formulation</h3>

            <h4 style="margin-top: 15px;">Affine Transformations</h4>
            <div class="formula-box">
a<sub>ℓ</sub> = W<sub>ℓ</sub> · z<sub>ℓ-1</sub> + b<sub>ℓ</sub>

Where:
• W<sub>ℓ</sub> is the weight matrix for layer ℓ
• b<sub>ℓ</sub> is the bias vector
• z<sub>ℓ-1</sub> is the output from the previous layer
            </div>

            <h4>GELU Activation Function</h4>
            <div class="formula-box">
GELU(x) = x · Φ(x)

Where Φ(x) is the CDF of the standard normal distribution.

<strong>Approximation used:</strong>
GELU(x) ≈ 0.5x(1 + tanh(√(2/π) · (x + 0.044715x³)))
            </div>

            <h4>Polytope Encoding of GELU</h4>
            <div class="formula-box">
For each neuron with pre-activation a and post-activation z:

<strong>Lower envelope:</strong>  z ≥ α<sub>L</sub> · a + β<sub>L</sub>
<strong>Upper envelope:</strong>  z ≤ α<sub>U</sub> · a + β<sub>U</sub>

Where α<sub>L</sub>, β<sub>L</sub>, α<sub>U</sub>, β<sub>U</sub> are computed using:
• Interval bounds [L, U] for a (from IBP)
• Tight linear envelopes that bound GELU over [L, U]

This replaces the nonlinear GELU with linear constraints!
            </div>

            <h4>Softmax (Post-processing)</h4>
            <div class="formula-box">
Softmax converts logits to probabilities:

p<sub>i</sub> = exp(a<sub>3</sub>[i]) / Σ<sub>j</sub> exp(a<sub>3</sub>[j])

Where:
• a<sub>3</sub>[i] is the logit for class i
• p<sub>i</sub> is the probability for class i
• Σ p<sub>i</sub> = 1

<strong>Note:</strong> The polytope operates on logits (a<sub>3</sub>), not probabilities.
Softmax is only used for final classification and visualization.
            </div>

            <h4>Network Forward Pass</h4>
            <div class="formula-box">
x<sub>0</sub> = input (49-dimensional, 7×7 flattened)

a<sub>1</sub> = W<sub>1</sub> · x<sub>0</sub> + b<sub>1</sub>  (shape: 3)
z<sub>1</sub> = GELU(a<sub>1</sub>)

a<sub>2</sub> = W<sub>2</sub> · z<sub>1</sub> + b<sub>2</sub>  (shape: 3)
z<sub>2</sub> = GELU(a<sub>2</sub>)

a<sub>3</sub> = W<sub>3</sub> · z<sub>2</sub> + b<sub>3</sub>  (shape: 10, output logits)

Prediction = argmax(a<sub>3</sub>)  [or argmax(Softmax(a<sub>3</sub>))]
            </div>
        </div>

        <div class="polytope-explanation">
            <h3>What is the Polytope?</h3>
            <p>
                A <strong>polytope</strong> is a geometric region defined by linear inequalities.
                For neural network verification, we construct a polytope that <em>over-approximates</em>
                all possible network behaviors for inputs in a given region.
            </p>

            <h4>Variables in our polytope:</h4>
            <ul style="margin-left: 20px; margin-bottom: 10px;">
                <li><code>x₀[i]</code> for i = 0..48: Input pixels (constrained to ε-ball around input)</li>
                <li><code>a₁[j], z₁[j]</code> for j = 0..2: Pre/post-activation for hidden layer 1</li>
                <li><code>a₂[k], z₂[k]</code> for k = 0..2: Pre/post-activation for hidden layer 2</li>
                <li><code>a₃[m]</code> for m = 0..9: Output logits (unbounded)</li>
            </ul>

            <h4>Constraints in our polytope:</h4>
            <ol style="margin-left: 20px;">
                <li><strong>Input box:</strong> <code>x₀[i] ∈ [x₀[i] - ε, x₀[i] + ε] ∩ [0, 1]</code> for all i</li>
                <li><strong>Affine relations:</strong> <code>a<sub>ℓ</sub> = W<sub>ℓ</sub> · z<sub>ℓ-1</sub> + b<sub>ℓ</sub></code> (equality constraints)</li>
                <li><strong>GELU envelopes:</strong> Linear lower/upper bounds on <code>z = GELU(a)</code></li>
            </ol>

            <p style="margin-top: 15px;">
                <strong>Why it's useful:</strong> Any output reachable by the network for inputs in the ε-ball
                is guaranteed to be in our polytope. This approach, inspired by
                <a href="https://ggndpsngh.github.io/files/DeepPoly.pdf" target="_blank" style="color: #007bff;">
                Singh et al.'s DeepPoly</a>, enables us to analyze network behavior through linear programming.
                Beyond verification, this representation provides <strong>interpretability</strong>: we can probe
                how individual neurons contribute to predictions by equipping the polytope with the right objective 
                functions and doing the optimization.
            </p>

            <p style="margin-top: 10px; font-size: 0.9em; color: #666;">
                Current demo uses ε = 0.01, giving 49 input constraints + 6 GELU envelope constraints (2 per neuron × 3 neurons in each hidden layer).
            </p>
        </div>

        <h2>Interactive Network Visualization</h2>
        <div class="legend">
            <div class="legend-item">
                <span>Node color:</span>
                <div class="color-bar"></div>
                <span>(Low → High activation)</span>
            </div>
            <div class="legend-item">
                <span style="color: blue;">━━</span> Positive weight
            </div>
            <div class="legend-item">
                <span style="color: red;">━━</span> Negative weight
            </div>
            <div class="legend-item">
                <span>Hover for details • Click hidden neurons for patterns</span>
            </div>
        </div>

        <div class="network-viz">
            <canvas id="networkCanvas" width="800" height="500"></canvas>
            <div>
                <div class="digit-display">
                    <strong>Current Digit:</strong>
                    <div id="digitLabel" style="font-size: 1.5em; margin: 5px 0;">0</div>
                    <canvas id="digitCanvas" class="digit-canvas" width="140" height="140"></canvas>
                    <div class="controls">
                        <button onclick="prevDigit()">Previous</button>
                        <button onclick="nextDigit()">Next</button>
                    </div>
                </div>
                <div class="info-panel" id="infoPanel">
                    Loading...
                </div>
            </div>
        </div>

        <h2>Mechanistic Interpretability</h2>
        <p>
            By stepping through the NN, we can understand how the network composes features
            to make predictions. Each hidden neuron learns interpretable patterns that combine to form
            digit classifiers. We formally verify these properties with the polytope.
        </p>

        <p style="margin-top: 10px;">
            <strong>Click on the hidden neurons</strong> in the visualization above to see what patterns they detect.
            The 6 hidden neurons (3 in each layer) learn distinct visual features:
        </p>

        <div class="mechanistic-formula">
            <strong>Example: How the network recognizes Digit 0</strong><br><br>
            Digit 0 ∝ (++ Frame) - (- Spine) - (- Belt)<br>
            <span style="font-size: 0.9em; color: #666;">Must act like a container &nbsp;&nbsp; Must have empty center &nbsp;&nbsp; Must have empty middle</span>
        </div>

        <img src="dashboard_digit_0.png" alt="Mechanistic trace for digit 0" style="max-width: 100%; border: 1px solid #ddd; border-radius: 4px; margin: 15px 0;">

        <p style="font-size: 0.9em; color: #666;">
            The dashboard shows how Layer 1 neurons detect basic patterns (Frame, Spine, Belt),
            and Layer 2 neurons combine them with learned weights to produce the final digit 0 logit.
            The network learns that digit 0 should strongly activate the "Frame" detector while
            avoiding activation of "Spine" and "Belt" detectors (which would indicate filled regions).
        </p>

        <div class="robustness-section">
            <h2>Robustness Analysis</h2>
            <p>
                The plot below shows <strong>robustness rates</strong> (percentage of test samples where the LP
                makes the correct prediction within an ε-ball) across different perturbation sizes for 600 test samples:
            </p>
            <img src="epsilon_robustness_full.png" alt="Robustness vs Perturbation Size">
            <p style="margin-top: 10px; font-size: 0.9em; color: #666;">
                <strong>Key findings:</strong> The LP maintains high accuracy for small perturbations (ε ≤ 0.02),
                with varying sensitivity across different digit classes. For example, digit 1 remains highly robust
                even at ε = 0.02, while digit 4 degrades more quickly. Even more interestingly, the LP appears to be
                a good classifier for the MNIST problem in and of itself. 
            </p>
        </div>
    </div>

    <div id="tooltip" class="tooltip"></div>

    <!-- Modal for neuron visualization -->
    <div id="neuronModal" class="modal">
        <div class="modal-content">
            <span class="modal-close" onclick="closeNeuronModal()">&times;</span>
            <div id="modalBody"></div>
        </div>
    </div>

    <script>
        // GELU activation function (matching Python implementation)
        function gelu(x) {
            const sqrt2pi = Math.sqrt(2 / Math.PI);
            return 0.5 * x * (1 + Math.tanh(sqrt2pi * (x + 0.044715 * x * x * x)));
        }

        // Matrix multiplication: result[j] = sum_i(a[i] * W[i][j])
        function matmul(a, W) {
            const result = new Array(W[0].length).fill(0);
            for (let j = 0; j < W[0].length; j++) {
                for (let i = 0; i < a.length; i++) {
                    result[j] += a[i] * W[i][j];
                }
            }
            return result;
        }

        // Add bias element-wise
        function addBias(a, b) {
            return a.map((val, i) => val + b[i]);
        }

        // Apply GELU element-wise
        function applyGelu(a) {
            return a.map(gelu);
        }

        // Normalize value to [0, 1] for color (sigmoid)
        function normalizeActivation(val) {
            return 1 / (1 + Math.exp(-val));
        }

        // Global state
        let weights = null;
        let mnistSamples = null;
        let currentIndex = 0;  // Index into samples array
        let activations = null;
        let neuronPositions = [];
        const canvas = document.getElementById('networkCanvas');
        const ctx = canvas.getContext('2d');
        const digitCanvas = document.getElementById('digitCanvas');
        const digitCtx = digitCanvas.getContext('2d');
        const epsilon = 0.01;

        // Forward pass (matching Python implementation)
        function forwardPass(input) {
            // Layer 1
            const a1 = addBias(matmul(input, weights.W1), weights.b1);
            const z1 = applyGelu(a1);

            // Layer 2
            const a2 = addBias(matmul(z1, weights.W2), weights.b2);
            const z2 = applyGelu(a2);

            // Output
            const a3 = addBias(matmul(z2, weights.W3), weights.b3);

            return { input, a1, z1, a2, z2, a3 };
        }

        // Draw network
        function drawNetwork() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const layerX = [80, 300, 520, 740];
            const layerSizes = [49, 3, 3, 10];
            const layerNames = ['Input\n(7×7)', 'Hidden 1\n(GELU)', 'Hidden 2\n(GELU)', 'Output\n(Logits)'];

            neuronPositions = [];

            // Calculate positions
            for (let layer = 0; layer < 4; layer++) {
                neuronPositions[layer] = [];
                const count = layerSizes[layer];
                const spacing = Math.min(400 / count, 30);
                const startY = 250 - (count - 1) * spacing / 2;

                for (let i = 0; i < count; i++) {
                    neuronPositions[layer].push({
                        x: layerX[layer],
                        y: startY + i * spacing
                    });
                }
            }

            // Draw edges
            const weightMatrices = [weights.W1, weights.W2, weights.W3];
            for (let layer = 0; layer < 3; layer++) {
                const W = weightMatrices[layer];
                for (let i = 0; i < W.length; i++) {
                    for (let j = 0; j < W[i].length; j++) {
                        const weight = W[i][j];
                        const from = neuronPositions[layer][i];
                        const to = neuronPositions[layer + 1][j];

                        ctx.strokeStyle = weight > 0 ? 'rgba(0, 100, 255, 0.3)' : 'rgba(255, 0, 0, 0.3)';
                        ctx.lineWidth = Math.min(Math.abs(weight) * 2, 2);

                        ctx.beginPath();
                        ctx.moveTo(from.x, from.y);
                        ctx.lineTo(to.x, to.y);
                        ctx.stroke();
                    }
                }
            }

            // Draw nodes
            const acts = [
                activations.input,
                activations.z1,
                activations.z2,
                activations.a3
            ];

            for (let layer = 0; layer < 4; layer++) {
                const values = acts[layer];
                for (let i = 0; i < neuronPositions[layer].length; i++) {
                    const pos = neuronPositions[layer][i];
                    const val = values[i];
                    const intensity = layer === 0 ? val : normalizeActivation(val);

                    // Color gradient from light yellow to red
                    const r = 255;
                    const g = Math.floor(255 - intensity * 200);
                    const b = Math.floor(224 - intensity * 224);

                    const radius = layerSizes[layer] > 10 ? 4 : (layerSizes[layer] > 5 ? 8 : 12);

                    ctx.fillStyle = `rgb(${r}, ${g}, ${b})`;
                    ctx.strokeStyle = '#000';
                    ctx.lineWidth = 1.5;

                    ctx.beginPath();
                    ctx.arc(pos.x, pos.y, radius, 0, Math.PI * 2);
                    ctx.fill();
                    ctx.stroke();
                }

                // Layer labels
                ctx.fillStyle = '#333';
                ctx.font = 'bold 12px Arial';
                ctx.textAlign = 'center';
                ctx.fillText(layerNames[layer].split('\n')[0], layerX[layer], 30);
                ctx.fillText(layerNames[layer].split('\n')[1], layerX[layer], 45);
            }
        }

        // Draw digit
        function drawDigit(digit) {
            const imgData = digitCtx.createImageData(7, 7);
            for (let i = 0; i < 49; i++) {
                const val = Math.floor(digit[i] * 255);
                imgData.data[i * 4] = val;
                imgData.data[i * 4 + 1] = val;
                imgData.data[i * 4 + 2] = val;
                imgData.data[i * 4 + 3] = 255;
            }
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = 7;
            tempCanvas.height = 7;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.putImageData(imgData, 0, 0);

            digitCtx.clearRect(0, 0, 140, 140);
            digitCtx.imageSmoothingEnabled = false;
            digitCtx.drawImage(tempCanvas, 0, 0, 7, 7, 0, 0, 140, 140);
        }

        // Update info panel
        function updateInfo(trueLabel) {
            const predicted = activations.a3.indexOf(Math.max(...activations.a3));
            const confidence = activations.a3[predicted];

            let info = `=== CURRENT DIGIT ===\n`;
            info += `True Label: ${trueLabel}\n`;
            info += `Predicted: ${predicted} ✓\n`;
            info += `Confidence: ${confidence.toFixed(3)}\n\n`;

            info += `=== OUTPUT LOGITS ===\n`;
            for (let i = 0; i < 10; i++) {
                const marker = i === predicted ? '→ ' : '  ';
                info += `${marker}${i}: ${activations.a3[i].toFixed(3)}\n`;
            }

            info += `\n=== POLYTOPE INFO ===\n`;
            info += `ε-ball: ${epsilon}\n`;
            info += `Variables: x0, a1, z1, a2, z2, a3\n`;
            info += `Constraints:\n`;
            info += `  - Input box: 49 vars\n`;
            info += `  - GELU env L1: 6 (2×3)\n`;
            info += `  - GELU env L2: 6 (2×3)\n`;

            document.getElementById('infoPanel').textContent = info;
        }

        // Update visualization
        function update() {
            const input = mnistSamples.samples[currentIndex];
            const trueLabel = mnistSamples.labels[currentIndex];
            activations = forwardPass(input);

            document.getElementById('digitLabel').textContent = trueLabel;
            drawDigit(input);
            drawNetwork();
            updateInfo(trueLabel);
        }

        // Navigation
        function nextDigit() {
            currentIndex = (currentIndex + 1) % mnistSamples.samples.length;
            update();
        }

        function prevDigit() {
            currentIndex = (currentIndex - 1 + mnistSamples.samples.length) % mnistSamples.samples.length;
            update();
        }

        // Neuron click handler for interpretability
        canvas.addEventListener('click', (e) => {
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;

            // Check if click is on a hidden neuron (layers 1 or 2)
            for (let layer = 1; layer <= 2; layer++) {
                for (let i = 0; i < neuronPositions[layer].length; i++) {
                    const pos = neuronPositions[layer][i];
                    const radius = 8; // Hidden layers have radius 8
                    const dist = Math.sqrt((x - pos.x) ** 2 + (y - pos.y) ** 2);

                    if (dist < radius * 1.5) {
                        showNeuronModal(layer, i);
                        return;
                    }
                }
            }
        });

        function showNeuronModal(layer, idx) {
            const modal = document.getElementById('neuronModal');
            const modalBody = document.getElementById('modalBody');

            const layerNames = ['L1', 'L2'];
            const neuronNames = [
                ['Frame', 'Spine', 'Belt'],  // L1 neurons
                ['N0', 'N1', 'N2']           // L2 neurons
            ];

            const title = `Layer ${layer} Neuron ${idx}: ${neuronNames[layer - 1][idx]}`;
            const imagePath = `neuron_L${layer}_N${idx}.png`;

            modalBody.innerHTML = `
                <h2>${title}</h2>
                <p>This neuron's activation pattern across different digits:</p>
                <img src="${imagePath}" alt="${title}" style="width: 100%; max-width: 1000px;">
                <p style="margin-top: 15px; color: #666; font-size: 0.95em;">
                    The visualization shows: (left) histograms of activation values for specific digits,
                    (center) mean activation by digit class, and (right) the input weight pattern showing
                    which pixels most influence this neuron.
                </p>
            `;

            modal.style.display = 'block';
        }

        function closeNeuronModal() {
            document.getElementById('neuronModal').style.display = 'none';
        }

        // Close modal when clicking outside
        window.onclick = function(event) {
            const modal = document.getElementById('neuronModal');
            if (event.target == modal) {
                modal.style.display = 'none';
            }
        }

        // Tooltip on hover
        canvas.addEventListener('mousemove', (e) => {
            const rect = canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;

            let found = false;
            for (let layer = 0; layer < neuronPositions.length; layer++) {
                for (let i = 0; i < neuronPositions[layer].length; i++) {
                    const pos = neuronPositions[layer][i];
                    const radius = [49, 3, 3, 10][layer] > 10 ? 4 : ([49, 3, 3, 10][layer] > 5 ? 8 : 12);
                    const dist = Math.sqrt((x - pos.x) ** 2 + (y - pos.y) ** 2);

                    if (dist < radius * 1.5) {
                        showTooltip(e.clientX, e.clientY, layer, i);
                        found = true;
                        break;
                    }
                }
                if (found) break;
            }

            if (!found) {
                document.getElementById('tooltip').style.display = 'none';
            }
        });

        function showTooltip(x, y, layer, idx) {
            const tooltip = document.getElementById('tooltip');
            const layerNames = ['Input', 'Hidden1', 'Hidden2', 'Output'];
            let text = `=== ${layerNames[layer]} Layer ===\nNeuron Index: ${idx}\n\n`;

            if (layer === 0) {
                text += `Variable: x0[${idx}]\n`;
                text += `Pixel position: (${Math.floor(idx/7)}, ${idx%7})\n`;
                text += `Value: ${activations.input[idx].toFixed(4)}\n\n`;
                text += `Polytope Constraints:\n`;
                const lb = Math.max(0, activations.input[idx] - epsilon).toFixed(4);
                const ub = Math.min(1, activations.input[idx] + epsilon).toFixed(4);
                text += `  ${lb} ≤ x0[${idx}] ≤ ${ub}`;
            } else if (layer === 1) {
                const neuronName = ['Frame', 'Spine', 'Belt'][idx];
                text += `Name: "${neuronName}"\n`;
                text += `Pre-activation: a1[${idx}]\n`;
                text += `Post-activation: z1[${idx}]\n`;
                text += `Activation: GELU(a1[${idx}])\n\n`;
                text += `Math:\n`;
                text += `  a1[${idx}] = Σ W1[i,${idx}]·x0[i] + b1[${idx}]\n`;
                text += `  z1[${idx}] = GELU(a1[${idx}])\n\n`;
                text += `Current Values:\n`;
                text += `  a1[${idx}] = ${activations.a1[idx].toFixed(4)}\n`;
                text += `  z1[${idx}] = ${activations.z1[idx].toFixed(4)}\n\n`;
                text += `Polytope Constraints:\n`;
                text += `  z1[${idx}] ≥ αL·a1[${idx}] + βL  (lower)\n`;
                text += `  z1[${idx}] ≤ αU·a1[${idx}] + βU  (upper)\n\n`;
                text += `Click to see activation patterns!`;
            } else if (layer === 2) {
                text += `Pre-activation: a2[${idx}]\n`;
                text += `Post-activation: z2[${idx}]\n`;
                text += `Activation: GELU(a2[${idx}])\n\n`;
                text += `Math:\n`;
                text += `  a2[${idx}] = Σ W2[i,${idx}]·z1[i] + b2[${idx}]\n`;
                text += `  z2[${idx}] = GELU(a2[${idx}])\n\n`;
                text += `Current Values:\n`;
                text += `  a2[${idx}] = ${activations.a2[idx].toFixed(4)}\n`;
                text += `  z2[${idx}] = ${activations.z2[idx].toFixed(4)}\n\n`;
                text += `Polytope Constraints:\n`;
                text += `  z2[${idx}] ≥ αL·a2[${idx}] + βL  (lower)\n`;
                text += `  z2[${idx}] ≤ αU·a2[${idx}] + βU  (upper)\n\n`;
                text += `Click to see activation patterns!`;
            } else {
                text += `Variable: a3[${idx}]\n`;
                text += `Meaning: Output logit for digit ${idx}\n\n`;
                text += `Math:\n`;
                text += `  a3[${idx}] = Σ W3[i,${idx}]·z2[i] + b3[${idx}]\n\n`;
                text += `Current Value: ${activations.a3[idx].toFixed(4)}\n\n`;
                text += `Polytope: No constraints\n`;
                text += `(Output logits are unbounded)`;
            }

            tooltip.textContent = text;
            tooltip.style.display = 'block';
            tooltip.style.left = (x + 15) + 'px';
            tooltip.style.top = (y - 15) + 'px';
        }

        // Load weights and samples, then initialize
        Promise.all([
            fetch('weights.json').then(r => r.json()),
            fetch('mnist_samples.json').then(r => r.json())
        ]).then(([weightsData, samplesData]) => {
            weights = weightsData;
            mnistSamples = samplesData;
            update();
        }).catch(err => {
            document.getElementById('infoPanel').textContent = 'Error loading data: ' + err;
        });
    </script>
</body>
</html>
